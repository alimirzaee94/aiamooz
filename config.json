{
  "openai_api_key": "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",
  "primary_model": "gpt-4.1",
  "fast_model": "gpt-4.1-mini",
  "embedding_model": "text-embedding-3-large",
  "temperature": 0.3,
  "max_tokens": 4000,
  "embedding_dimension": 3072,
  "request_timeout": 30,
  "enable_orchestrator": true,
  "enable_narrative_mode": true,
  "enable_context_analysis": true,
  "enable_quality_assurance": true,
  "enable_casual_chat": true,
  "enable_universal_intelligence": true,
  "enable_advanced_memory": true,
  "enable_emotional_intelligence": true,
  "enable_greeting_module": true,
  "retrieval_top_k": 20,
  "rerank_top_k": 10,
  "final_top_k": 5,
  "min_relevance_score": 0.65,
  "reranker_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
  "enable_cache": true,
  "cache_ttl": 3600,
  "max_concurrent_requests": 10,
  "browser_cache_enabled": true,
  "quality_thresholds": {
    "minimum": 0.6,
    "target": 0.8,
    "approval": 0.7
  },
  "prompts_config_path": "prompts_config.json"
}